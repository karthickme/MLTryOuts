{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather compilation project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Dayton - Environmental Protection Agency Average Daily Temperature Archive,\n",
    "http://academic.udayton.edu/kissock/http/Weather/default.htm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above link hosts average Daily temperature for many countries, Will start to explore and persome some analysis on the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Brief description of weather data and sources</h2>\n",
    "\n",
    "<p><br>\n",
    "This archive contains files of average daily temperatures for 157 <st1:country-region\n",
    "w:st=\"on\"><st1:place w:st=\"on\">U.S.</st1:place></st1:country-region> and 167 international\n",
    "cities. Source data for these files are from the Global Summary of the Day\n",
    "(GSOD) database archived by the National Climatic Data Center (NCDC).<span\n",
    "style='mso-spacerun:yes'>&nbsp; </span>The average daily temperatures posted on\n",
    "this site are computed from 24 hourly temperature readings in the Global\n",
    "Summary of the Day (GSOD) data.</p>\n",
    "\n",
    "<p>The data fields in each file posted on this site are: month, day, year,\n",
    "average daily temperature (F).<span style='mso-spacerun:yes'>&nbsp; </span>We\n",
    "use &quot;-99&quot; as a no-data flag when data are not available. </p>\n",
    "\n",
    "<div class=MsoNormal align=center style='text-align:center'>\n",
    "\n",
    "<hr size=2 width=\"100%\" align=center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<p class=MsoNormal><o:p>&nbsp;</o:p></p>\n",
    "\n",
    "<h2>Comparison of &#8220;24 hour&#8221; and &#8220;(min + max) / 2&#8221;\n",
    "average daily temperatures</h2>\n",
    "\n",
    "<p class=MsoNormal><o:p>&nbsp;</o:p></p>\n",
    "\n",
    "<p class=MsoNormal>The average daily temperatures posted on this site are from\n",
    "Global Summary of the Day (GSOD) dataset and are computed from 24 hourly\n",
    "temperature readings. The GSOD dataset also includes daily minimum and maximum\n",
    "temperatures.<span style='mso-spacerun:yes'>&nbsp; </span>Some earlier datasets\n",
    "compiled by the NCDC, such as the Local <span class=SpellE>Climatological</span>\n",
    "Data Monthly Summary, contained daily minimum and maximum temperatures, but did\n",
    "not contain the average daily temperature computed from 24 hourly\n",
    "readings.<span style='mso-spacerun:yes'>&nbsp; </span>As a result, some users\n",
    "calculated the average daily temperature as the average of the daily minimum and\n",
    "maximum temperatures.</p>\n",
    "\n",
    "<p>We compared average daily temperatures calculated from 24 hourly readings,\n",
    "T24, to average daily temperatures calculated as the average of the daily\n",
    "minimum and maximum temperatures, <span class=SpellE>Tminmax</span>, for 53,004\n",
    "daily temperature records in the GSOD dataset.<span\n",
    "style='mso-spacerun:yes'>&nbsp; </span>We found that, on average, the absolute\n",
    "value of the deviation between T24 and <span class=SpellE>Tminmax</span> was\n",
    "1.48 F.<span style='mso-spacerun:yes'>&nbsp; </span>In addition, we found that,\n",
    "on average, <span class=SpellE>Tminmax</span> was 0.0790 F higher than T24.\n",
    "Temperatures in the GSOD dataset are reported with a precision of 0.1 F.<span\n",
    "style='mso-spacerun:yes'>&nbsp; </span>Thus, the average bias is less than the\n",
    "precision of the source data, and we conclude that the bias between T24 and <span\n",
    "class=SpellE>Tminmax</span> is not statistically significant.<span\n",
    "style='mso-spacerun:yes'>&nbsp; </span>If the bias is negligible, then the\n",
    "deviation is random and will sum to zero over any sufficiently long time\n",
    "period.<span style='mso-spacerun:yes'>&nbsp; </span>Thus, use of either T24 or <span\n",
    "class=SpellE>Tminmax</span> &#8220;average&#8221; daily temperatures should\n",
    "give similar results.<span style='mso-spacerun:yes'>&nbsp;&nbsp;&nbsp; </span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan at this point of time\n",
    "1. Analyse the page understand the page setup\n",
    "2. Then use bs4 to get the link download the contents and extract get a dataframe out of this.\n",
    "3. Then lets see how it progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting Non US data first\n",
    "url = 'https://academic.udayton.edu/kissock/http/Weather/citylistWorld.htm'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, features=\"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = soup.find_all(\"li\",class_=\"MsoNormal\")\n",
    "# base_url = \"https://academic.udayton.edu/kissock/http/Weather/\"  # commenting as the way data pull is changed.\n",
    "all_cities = []\n",
    "# all_links = []\n",
    "all_filename = []\n",
    "all_countries = []\n",
    "for city in cities:\n",
    "    city_name = city.text.split(\"(\")[0].rstrip()\n",
    "    all_cities.append(city_name)\n",
    "    # link = city.find('a')['href']    # commenting as the way data pull is changed.\n",
    "    filename = city.find('a')['href'].split('/')[-1]\n",
    "    all_filename.append(filename)\n",
    "    # page is having multiple a links in each case but the city is presendin in just 1 a tag so did some stupid workaround which works!!\n",
    "    country = city.find_all(\"a\")[-1].text[:2].strip() + city.find_all(\"a\")[0].text[:2].strip() \n",
    "    # all_links.append(base_url + link)   # commenting as the way data pull is changed.\n",
    "    all_countries.append(country[:2])\n",
    "# print(len(all_cities))\n",
    "# print(len(all_filename))\n",
    "# print(len(all_countries))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change of plan\n",
    "\n",
    "\n",
    "Got to know a single place to download the data but there are some conuntry code and US City code conflict. so preparing them 1ft\n",
    "- So going with only non US Cities first < br >\n",
    "- One that is completed then will work on US cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "158\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "# collecting US data\n",
    "url = 'https://academic.udayton.edu/kissock/http/Weather/citylistUS.htm'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, features=\"lxml\")\n",
    "cities = soup.find_all(\"li\", class_=\"MsoNormal\")\n",
    "all_UScities = []\n",
    "all_USfilename = []\n",
    "all_USstate = []\n",
    "for city in cities:\n",
    "    city_name = city.text.split(\"(\")[0].rstrip()\n",
    "    all_UScities.append(city_name)\n",
    "    # link = city.find('a')['href']    # commenting as the way data pull is changed.\n",
    "    filename = city.find('a')['href'].split('/')[-1]\n",
    "    all_USfilename.append(filename)\n",
    "    # page is having multiple a links in each case but the city is presendin in just 1 a tag so did some stupid workaround which works!!\n",
    "    state = city.find_all(\"a\")[-1].text[:2].strip() + \\\n",
    "        city.find_all(\"a\")[0].text[:2].strip()\n",
    "    # all_links.append(base_url + link)   # commenting as the way data pull is changed.\n",
    "    all_USstate.append(state[:2])\n",
    "print(len(all_UScities))\n",
    "print(len(all_USfilename))\n",
    "print(len(all_USstate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site is slow, So sending 300+ requests(Mulitple time when testing does not seems to fair) will be huge so planned to download the entire data use the file name to read from file specifically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So steps to do now..\n",
    "\n",
    "1. Download the entire file with all the data\n",
    "2. Unzip the file to a data directory\n",
    "3. fileformat \n",
    "   1. US Data --> SSCCCCCC.txt (SS-State abbreviation CCCCCC-City abbreviation up to 6 letters). \n",
    "   2. Internatinal data -->  SSCCCCCC.txt (SS-Country abbreviation CCCCCC-City abbreviation up to 6 letters).\n",
    "4. create two dataframe one for US and other international with datetime series as index, colums will each of the city \n",
    "5. Get country code - counntry reff and US state code and States name from a relaible source for plotting\n",
    "6. Then begin with plotting to see if there are any pattern\n",
    "7. other steps will be determined futher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file Already present\n"
     ]
    }
   ],
   "source": [
    "# importing the requests module\n",
    "import requests\n",
    "url = \"https://academic.udayton.edu/kissock/http/Weather/gsod95-current/allsites.zip\"\n",
    "\n",
    "if os.path.exists('allsites.zip'):\n",
    "    print(\"file Already present\")\n",
    "else:\n",
    "    print('Downloading started')\n",
    "    # Downloading the file by sending the request to the URL\n",
    "    req = requests.get(url)\n",
    "\n",
    "    # Split URL to get the file name\n",
    "    filename = url.split('/')[-1]\n",
    "\n",
    "    # Writing the file to the local file system\n",
    "    with open(filename, 'wb') as output_file:\n",
    "        output_file.write(req.content)\n",
    "    print('Downloading Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allsites.zip\n",
      "Extracted all\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "filename = \"allsites.zip\"\n",
    "print(filename)\n",
    "try:\n",
    "    with zipfile.ZipFile(filename) as z:\n",
    "        z.extractall('data/03Temperature')\n",
    "        print(\"Extracted all\")\n",
    "except:\n",
    "    print(\"Invalid file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alpha-2 code</th>\n",
       "      <th>Alpha-3 code</th>\n",
       "      <th>Numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "      <td>ALA</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>WF</td>\n",
       "      <td>WLF</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>EH</td>\n",
       "      <td>ESH</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>YE</td>\n",
       "      <td>YEM</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZM</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Country Alpha-2 code Alpha-3 code  Numeric\n",
       "0          Afghanistan           AF          AFG        4\n",
       "1        Åland Islands           AX          ALA      248\n",
       "2              Albania           AL          ALB        8\n",
       "3              Algeria           DZ          DZA       12\n",
       "4       American Samoa           AS          ASM       16\n",
       "..                 ...          ...          ...      ...\n",
       "244  Wallis and Futuna           WF          WLF      876\n",
       "245     Western Sahara           EH          ESH      732\n",
       "246              Yemen           YE          YEM      887\n",
       "247             Zambia           ZM          ZMB      894\n",
       "248           Zimbabwe           ZW          ZWE      716\n",
       "\n",
       "[249 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# County code https://www.iban.com/country-codes\n",
    "import pandas as pd\n",
    "url = \"https://www.iban.com/country-codes\"\n",
    "\n",
    "country_code = pd.read_html(url)[0]\n",
    "\n",
    "country_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State or Region Code</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>Armed Forces America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>Armed Forces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP</td>\n",
       "      <td>Armed Forces Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DC</td>\n",
       "      <td>Washington DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DE</td>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GA</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GU</td>\n",
       "      <td>Guam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HI</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IA</td>\n",
       "      <td>Iowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID</td>\n",
       "      <td>Idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IN</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KS</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KY</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ME</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MN</td>\n",
       "      <td>Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MS</td>\n",
       "      <td>Mississippi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MT</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ND</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NH</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NM</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NV</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>OK</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OR</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RI</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SC</td>\n",
       "      <td>South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VI</td>\n",
       "      <td>Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VT</td>\n",
       "      <td>Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>WI</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State or Region Code                  Name\n",
       "0                    AA  Armed Forces America\n",
       "1                    AE          Armed Forces\n",
       "2                    AK                Alaska\n",
       "3                    AL               Alabama\n",
       "4                    AP  Armed Forces Pacific\n",
       "5                    AR              Arkansas\n",
       "6                    AZ               Arizona\n",
       "7                    CA            California\n",
       "8                    CO              Colorado\n",
       "9                    CT           Connecticut\n",
       "10                   DC         Washington DC\n",
       "11                   DE              Delaware\n",
       "12                   FL               Florida\n",
       "13                   GA               Georgia\n",
       "14                   GU                  Guam\n",
       "15                   HI                Hawaii\n",
       "16                   IA                  Iowa\n",
       "17                   ID                 Idaho\n",
       "18                   IL              Illinois\n",
       "19                   IN               Indiana\n",
       "20                   KS                Kansas\n",
       "21                   KY              Kentucky\n",
       "22                   LA             Louisiana\n",
       "23                   MA         Massachusetts\n",
       "24                   MD              Maryland\n",
       "25                   ME                 Maine\n",
       "26                   MI              Michigan\n",
       "27                   MN             Minnesota\n",
       "28                   MO              Missouri\n",
       "29                   MS           Mississippi\n",
       "30                   MT               Montana\n",
       "31                   NC        North Carolina\n",
       "32                   ND          North Dakota\n",
       "33                   NE              Nebraska\n",
       "34                   NH         New Hampshire\n",
       "35                   NJ            New Jersey\n",
       "36                   NM            New Mexico\n",
       "37                   NV                Nevada\n",
       "38                   NY              New York\n",
       "39                   OH                  Ohio\n",
       "40                   OK              Oklahoma\n",
       "41                   OR                Oregon\n",
       "42                   PA          Pennsylvania\n",
       "43                   PR           Puerto Rico\n",
       "44                   RI          Rhode Island\n",
       "45                   SC        South Carolina\n",
       "46                   SD          South Dakota\n",
       "47                   TN             Tennessee\n",
       "48                   TX                 Texas\n",
       "49                   UT                  Utah\n",
       "50                   VA              Virginia\n",
       "51                   VI        Virgin Islands\n",
       "52                   VT               Vermont\n",
       "53                   WA            Washington\n",
       "54                   WI             Wisconsin\n",
       "55                   WV         West Virginia\n",
       "56                   WY               Wyoming"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = r'https://knowledgecenter.zuora.com/BB_Introducing_Z_Business/D_Country%2C_State%2C_and_Province_Codes/B_State_Names_and_2-Digit_Codes'\n",
    "\n",
    "US_State_code = pd.read_html(url)[0]\n",
    "US_State_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanup of the read txt file\n",
    "\n",
    "Below function createcsv will read the txt files extracted and coverets to a CSV, with correct date foramt and the temperature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def createcsv(path):\n",
    "    \"\"\"Received one parameter, convers the these files to a proper CSV! \"\"\"\n",
    "    templist = []\n",
    "    file = open(path, \"r\")\n",
    "    if path[-3:] == \"LOG\":\n",
    "        return 0\n",
    "    print(f\"started {path}\", end=\" **\")\n",
    "    while(True):\n",
    "        # read next line\n",
    "        line = file.readline()\n",
    "        # check if line is not null\n",
    "        if not line or line.strip() == \"\":\n",
    "            break\n",
    "        numbers = re.findall('[-.0-9]+', line)\n",
    "        if int(numbers[1]) == 0:  # Dirty xix to address a erorr date issue in CUHAVANA.txt\n",
    "            # Dirty xix to address a erorr date issue in CUHAVANA.txt and DLHAMBUR.txt\n",
    "            numbers[1] = 29\n",
    "        if int(numbers[2]) == 201:\n",
    "            continue\n",
    "        # print(numbers)\n",
    "        col1 = datetime.date(\n",
    "            int(numbers[2]), int(numbers[0]), int(numbers[1]))\n",
    "        col2 = float(numbers[-1])\n",
    "        # print(col1, col2)\n",
    "        templist.append([col1,col2])\n",
    "    # print(templist[:5])\n",
    "    print(end=\" ** \")\n",
    "    tempdf = pd.DataFrame(templist,columns=['date', 'temp'])\n",
    "    # print(path[:-3]+\"csv\")\n",
    "    # tempdf.to_csv(\"00_deleteme.csv\",index=False)\n",
    "    tempdf.to_csv(path[:-3]+\"csv\", index=False)\n",
    "    print(end=\"**\")\n",
    "    print(end=\"**\")\n",
    "    file.close()\n",
    "    print(end=\" ** \")\n",
    "    os.remove(path)\n",
    "    print(\" done with \" + path[19:-3]+\"csv\")\n",
    "\n",
    "\n",
    "# createcsv('data/03Temperature/ABTIRANA.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started data/03Temperature/ABTIRANA.txt ** ** **** **  done with ABTIRANA.csv\n",
      "started data/03Temperature/AGBUENOS.txt ** ** **** **  done with AGBUENOS.csv\n",
      "started data/03Temperature/AKANCHOR.txt ** ** **** **  done with AKANCHOR.csv\n",
      "started data/03Temperature/AKFAIRBA.txt ** ** **** **  done with AKFAIRBA.csv\n",
      "started data/03Temperature/AKJUNEAU.txt ** ** **** **  done with AKJUNEAU.csv\n",
      "started data/03Temperature/ALALGIER.txt ** ** **** **  done with ALALGIER.csv\n",
      "started data/03Temperature/ALBIRMIN.txt ** ** **** **  done with ALBIRMIN.csv\n",
      "started data/03Temperature/ALHUNTSV.txt ** ** **** **  done with ALHUNTSV.csv\n",
      "started data/03Temperature/ALMOBILE.txt ** ** **** **  done with ALMOBILE.csv\n",
      "started data/03Temperature/ALMONTGO.txt ** ** **** **  done with ALMONTGO.csv\n",
      "started data/03Temperature/ARFTSMIT.txt ** ** **** **  done with ARFTSMIT.csv\n",
      "started data/03Temperature/ARLIROCK.txt ** ** **** **  done with ARLIROCK.csv\n",
      "started data/03Temperature/AUBRSBAN.txt ** ** **** **  done with AUBRSBAN.csv\n",
      "started data/03Temperature/AUCNBERA.txt ** ** **** **  done with AUCNBERA.csv\n",
      "started data/03Temperature/AUMELBRN.txt ** ** **** **  done with AUMELBRN.csv\n",
      "started data/03Temperature/AUPERTH.txt ** ** **** **  done with AUPERTH.csv\n",
      "started data/03Temperature/AUSYDNEY.txt ** ** **** **  done with AUSYDNEY.csv\n",
      "started data/03Temperature/AZFLAGST.txt ** ** **** **  done with AZFLAGST.csv\n",
      "started data/03Temperature/AZPHOENI.txt ** ** **** **  done with AZPHOENI.csv\n",
      "started data/03Temperature/AZTUCSON.txt ** ** **** **  done with AZTUCSON.csv\n",
      "started data/03Temperature/AZYUMA.txt ** ** **** **  done with AZYUMA.csv\n",
      "started data/03Temperature/BANASSAU.txt ** ** **** **  done with BANASSAU.csv\n",
      "started data/03Temperature/BEHMLTON.txt ** ** **** **  done with BEHMLTON.csv\n",
      "started data/03Temperature/BHBELIZE.txt ** ** **** **  done with BHBELIZE.csv\n",
      "started data/03Temperature/BIBJMBRA.txt ** ** **** **  done with BIBJMBRA.csv\n",
      "started data/03Temperature/BJCOTNOU.txt ** ** **** **  done with BJCOTNOU.csv\n",
      "started data/03Temperature/BMRNGOON.txt ** ** **** **  done with BMRNGOON.csv\n",
      "started data/03Temperature/BNMANAMA.txt ** ** **** **  done with BNMANAMA.csv\n",
      "started data/03Temperature/BOLAPAZ.txt ** ** **** **  done with BOLAPAZ.csv\n",
      "started data/03Temperature/BRBRGTWN.txt ** ** **** **  done with BRBRGTWN.csv\n",
      "started data/03Temperature/BUSOFIA.txt ** ** **** **  done with BUSOFIA.csv\n",
      "started data/03Temperature/BWDHAKA.txt ** ** **** **  done with BWDHAKA.csv\n",
      "started data/03Temperature/BXBRUSSL.txt ** ** **** **  done with BXBRUSSL.csv\n",
      "started data/03Temperature/BYMINSK.txt ** ** **** **  done with BYMINSK.csv\n",
      "started data/03Temperature/BZBRSLIA.txt ** ** **** **  done with BZBRSLIA.csv\n",
      "started data/03Temperature/BZRIODJN.txt ** ** **** **  done with BZRIODJN.csv\n",
      "started data/03Temperature/BZSAOPLO.txt ** ** **** **  done with BZSAOPLO.csv\n",
      "started data/03Temperature/CAFRESNO.txt ** ** **** **  done with CAFRESNO.csv\n",
      "started data/03Temperature/CALOSANG.txt ** ** **** **  done with CALOSANG.csv\n",
      "started data/03Temperature/CASACRAM.txt ** ** **** **  done with CASACRAM.csv\n",
      "started data/03Temperature/CASANDIE.txt ** ** **** **  done with CASANDIE.csv\n",
      "started data/03Temperature/CASANFRA.txt ** ** **** **  done with CASANFRA.csv\n",
      "started data/03Temperature/CEBANGUI.txt ** ** **** **  done with CEBANGUI.csv\n",
      "started data/03Temperature/CGBRZAVL.txt ** ** **** **  done with CGBRZAVL.csv\n",
      "started data/03Temperature/CIBIEJNG.txt ** ** **** **  done with CIBIEJNG.csv\n",
      "started data/03Temperature/CICHNGDU.txt ** ** **** **  done with CICHNGDU.csv\n",
      "started data/03Temperature/CIGNGZHO.txt ** ** **** **  done with CIGNGZHO.csv\n",
      "started data/03Temperature/CISHANGH.txt ** ** **** **  done with CISHANGH.csv\n",
      "started data/03Temperature/CISHNYNG.txt ** ** **** **  done with CISHNYNG.csv\n",
      "started data/03Temperature/CNCALGRY.txt ** ** **** **  done with CNCALGRY.csv\n",
      "started data/03Temperature/CNEDMNTN.txt ** ** **** **  done with CNEDMNTN.csv\n",
      "started data/03Temperature/CNHLIFAX.txt ** ** **** **  done with CNHLIFAX.csv\n",
      "started data/03Temperature/CNMONTRL.txt ** ** **** **  done with CNMONTRL.csv\n",
      "started data/03Temperature/CNOTTOWA.txt ** ** **** **  done with CNOTTOWA.csv\n",
      "started data/03Temperature/CNQUEBEC.txt ** ** **** **  done with CNQUEBEC.csv\n",
      "started data/03Temperature/CNREGINA.txt ** ** **** **  done with CNREGINA.csv\n",
      "started data/03Temperature/CNTORONT.txt ** ** **** **  done with CNTORONT.csv\n",
      "started data/03Temperature/CNVANCVR.txt ** ** **** **  done with CNVANCVR.csv\n",
      "started data/03Temperature/CNWINNPG.txt ** ** **** **  done with CNWINNPG.csv\n",
      "started data/03Temperature/COBOGOTA.txt ** ** **** **  done with COBOGOTA.csv\n",
      "started data/03Temperature/COCOSPGS.txt ** ** **** **  done with COCOSPGS.csv\n",
      "started data/03Temperature/CODENVER.txt ** ** **** **  done with CODENVER.csv\n",
      "started data/03Temperature/COGRNDJU.txt ** ** **** **  done with COGRNDJU.csv\n",
      "started data/03Temperature/COPUEBLO.txt ** ** **** **  done with COPUEBLO.csv\n",
      "started data/03Temperature/CSSANJOS.txt ** ** **** **  done with CSSANJOS.csv\n",
      "started data/03Temperature/CTBRIDGE.txt ** ** **** **  done with CTBRIDGE.csv\n",
      "started data/03Temperature/CTHARTFO.txt ** ** **** **  done with CTHARTFO.csv\n",
      "started data/03Temperature/CUHAVANA.txt ** ** **** **  done with CUHAVANA.csv\n",
      "started data/03Temperature/CYNICOSI.txt ** ** **** **  done with CYNICOSI.csv\n",
      "started data/03Temperature/CZBRTSLV.txt ** ** **** **  done with CZBRTSLV.csv\n",
      "started data/03Temperature/CZPRAGUE.txt ** ** **** **  done with CZPRAGUE.csv\n",
      "started data/03Temperature/DEWILMIN.txt ** ** **** **  done with DEWILMIN.csv\n",
      "started data/03Temperature/DLBONN.txt ** ** **** **  done with DLBONN.csv\n",
      "started data/03Temperature/DLFRNKFT.txt ** ** **** **  done with DLFRNKFT.csv\n",
      "started data/03Temperature/DLHAMBUR.txt ** ** **** **  done with DLHAMBUR.csv\n",
      "started data/03Temperature/DLMUNICH.txt ** ** **** **  done with DLMUNICH.csv\n",
      "started data/03Temperature/DNCOPNHG.txt ** ** **** **  done with DNCOPNHG.csv\n",
      "started data/03Temperature/DRSNTODM.txt ** ** **** **  done with DRSNTODM.csv\n",
      "started data/03Temperature/EGCAIRO.txt ** ** **** **  done with EGCAIRO.csv\n",
      "started data/03Temperature/EQGUAYQL.txt ** ** **** **  done with EQGUAYQL.csv\n",
      "started data/03Temperature/EQQUITO.txt ** ** **** **  done with EQQUITO.csv\n",
      "started data/03Temperature/ERABUDBI.txt ** ** **** **  done with ERABUDBI.csv\n",
      "started data/03Temperature/ERDUBAI.txt ** ** **** **  done with ERDUBAI.csv\n",
      "started data/03Temperature/ETADSABA.txt ** ** **** **  done with ETADSABA.csv\n",
      "started data/03Temperature/FIHELSIN.txt ** ** **** **  done with FIHELSIN.csv\n",
      "started data/03Temperature/FLDAYTNA.txt ** ** **** **  done with FLDAYTNA.csv\n",
      "started data/03Temperature/FLJACKSV.txt ** ** **** **  done with FLJACKSV.csv\n",
      "started data/03Temperature/FLMIAMIB.txt ** ** **** **  done with FLMIAMIB.csv\n",
      "started data/03Temperature/FLORLAND.txt ** ** **** **  done with FLORLAND.csv\n",
      "started data/03Temperature/FLTALLAH.txt ** ** **** **  done with FLTALLAH.csv\n",
      "started data/03Temperature/FLTAMPA.txt ** ** **** **  done with FLTAMPA.csv\n",
      "started data/03Temperature/FLWPALMB.txt ** ** **** **  done with FLWPALMB.csv\n",
      "started data/03Temperature/FRBRDAUX.txt ** ** **** **  done with FRBRDAUX.csv\n",
      "started data/03Temperature/FRPARIS.txt ** ** **** **  done with FRPARIS.csv\n",
      "started data/03Temperature/GAATLANT.txt ** ** **** **  done with GAATLANT.csv\n",
      "started data/03Temperature/GACOLMBS.txt ** ** **** **  done with GACOLMBS.csv\n",
      "started data/03Temperature/GAMACON.txt ** ** **** **  done with GAMACON.csv\n",
      "started data/03Temperature/GASAVANN.txt ** ** **** **  done with GASAVANN.csv\n",
      "started data/03Temperature/GBBANJUL.txt ** ** **** **  done with GBBANJUL.csv\n",
      "started data/03Temperature/GNCONKRY.txt ** ** **** **  done with GNCONKRY.csv\n",
      "started data/03Temperature/GOLIBRVL.txt ** ** **** **  done with GOLIBRVL.csv\n",
      "started data/03Temperature/GRATHENS.txt ** ** **** **  done with GRATHENS.csv\n",
      "started data/03Temperature/GUGUATML.txt ** ** **** **  done with GUGUATML.csv\n",
      "started data/03Temperature/GWBISSAU.txt ** ** **** **  done with GWBISSAU.csv\n",
      "started data/03Temperature/GYGRGTWN.txt ** ** **** **  done with GYGRGTWN.csv\n",
      "started data/03Temperature/HAPORTAP.txt ** ** **** **  done with HAPORTAP.csv\n",
      "started data/03Temperature/HIHONOLU.txt ** ** **** **  done with HIHONOLU.csv\n",
      "started data/03Temperature/HKHONGKG.txt ** ** **** **  done with HKHONGKG.csv\n",
      "started data/03Temperature/HOTEGUCI.txt ** ** **** **  done with HOTEGUCI.csv\n",
      "started data/03Temperature/HUBUDPST.txt ** ** **** **  done with HUBUDPST.csv\n",
      "started data/03Temperature/IADESMOI.txt ** ** **** **  done with IADESMOI.csv\n",
      "started data/03Temperature/IASIOCTY.txt ** ** **** **  done with IASIOCTY.csv\n",
      "started data/03Temperature/IDBOISE.txt ** ** **** **  done with IDBOISE.csv\n",
      "started data/03Temperature/IDJAKRTA.txt ** ** **** **  done with IDJAKRTA.csv\n",
      "started data/03Temperature/IDPOCATE.txt ** ** **** **  done with IDPOCATE.csv\n",
      "started data/03Temperature/IEDUBLIN.txt ** ** **** **  done with IEDUBLIN.csv\n",
      "started data/03Temperature/ILCHICAG.txt ** ** **** **  done with ILCHICAG.csv\n",
      "started data/03Temperature/ILPEORIA.txt ** ** **** **  done with ILPEORIA.csv\n",
      "started data/03Temperature/ILREYKJV.txt ** ** **** **  done with ILREYKJV.csv\n",
      "started data/03Temperature/ILROCKFO.txt ** ** **** **  done with ILROCKFO.csv\n",
      "started data/03Temperature/ILSPRING.txt ** ** **** **  done with ILSPRING.csv\n",
      "started data/03Temperature/INBOMBAY.txt ** ** **** **  done with INBOMBAY.csv\n",
      "started data/03Temperature/INCALCUT.txt ** ** **** **  done with INCALCUT.csv\n",
      "started data/03Temperature/INCHENAI.txt ** ** **** **  done with INCHENAI.csv\n",
      "started data/03Temperature/INDELHI.txt ** ** **** **  done with INDELHI.csv\n",
      "started data/03Temperature/INEVANSV.txt ** ** **** **  done with INEVANSV.csv\n",
      "started data/03Temperature/INFTWAYN.txt ** ** **** **  done with INFTWAYN.csv\n",
      "started data/03Temperature/ININDIAN.txt ** ** **** **  done with ININDIAN.csv\n",
      "started data/03Temperature/INSOBEND.txt ** ** **** **  done with INSOBEND.csv\n",
      "started data/03Temperature/ISTELAVI.txt ** ** **** **  done with ISTELAVI.csv\n",
      "started data/03Temperature/ISTELAVIV.txt ** ** **** **  done with ISTELAVIV.csv\n",
      "started data/03Temperature/IVABIDJN.txt ** ** **** **  done with IVABIDJN.csv\n",
      "started data/03Temperature/IYMILAN.txt ** ** **** **  done with IYMILAN.csv\n",
      "started data/03Temperature/IYROME.txt ** ** **** **  done with IYROME.csv\n",
      "started data/03Temperature/JDAMMAN.txt ** ** **** **  done with JDAMMAN.csv\n",
      "started data/03Temperature/JPOSAKA.txt ** ** **** **  done with JPOSAKA.csv\n",
      "started data/03Temperature/JPSAPPOR.txt ** ** **** **  done with JPSAPPOR.csv\n",
      "started data/03Temperature/JPTOKYO.txt ** ** **** **  done with JPTOKYO.csv\n",
      "started data/03Temperature/KNNAIROB.txt ** ** **** **  done with KNNAIROB.csv\n",
      "started data/03Temperature/KOSEOUL.txt ** ** **** **  done with KOSEOUL.csv\n",
      "started data/03Temperature/KRPYGYNG.txt ** ** **** **  done with KRPYGYNG.csv\n",
      "started data/03Temperature/KSGOODLA.txt ** ** **** **  done with KSGOODLA.csv\n",
      "started data/03Temperature/KSTOPEKA.txt ** ** **** **  done with KSTOPEKA.csv\n",
      "started data/03Temperature/KSWICHIT.txt ** ** **** **  done with KSWICHIT.csv\n",
      "started data/03Temperature/KWKUWAIT.txt ** ** **** **  done with KWKUWAIT.csv\n",
      "started data/03Temperature/KYLEXING.txt ** ** **** **  done with KYLEXING.csv\n",
      "started data/03Temperature/KYLOUISV.txt ** ** **** **  done with KYLOUISV.csv\n",
      "started data/03Temperature/KYPADUCA.txt ** ** **** **  done with KYPADUCA.csv\n",
      "started data/03Temperature/LABATONR.txt ** ** **** **  done with LABATONR.csv\n",
      "started data/03Temperature/LALAKECH.txt ** ** **** **  done with LALAKECH.csv\n",
      "started data/03Temperature/LANEWORL.txt ** ** **** **  done with LANEWORL.csv\n",
      "started data/03Temperature/LASHREVE.txt ** ** **** **  done with LASHREVE.csv\n",
      "started data/03Temperature/LAVIENTN.txt ** ** **** **  done with LAVIENTN.csv\n",
      "started data/03Temperature/LBBEIRUT.txt ** ** **** **  done with LBBEIRUT.csv\n",
      "started data/03Temperature/MABOSTON.txt ** ** **** **  done with MABOSTON.csv\n",
      "started data/03Temperature/MCRABAT.txt ** ** **** **  done with MCRABAT.csv\n",
      "started data/03Temperature/MDBALTIM.txt ** ** **** **  done with MDBALTIM.csv\n",
      "started data/03Temperature/MDWASHDC.txt ** ** **** **  done with MDWASHDC.csv\n",
      "started data/03Temperature/MECARIBO.txt ** ** **** **  done with MECARIBO.csv\n",
      "started data/03Temperature/MEPORTLA.txt ** ** **** **  done with MEPORTLA.csv\n",
      "started data/03Temperature/MGANTRVO.txt ** ** **** **  done with MGANTRVO.csv\n",
      "started data/03Temperature/MIDETROI.txt ** ** **** **  done with MIDETROI.csv\n",
      "started data/03Temperature/MIFLINT.txt ** ** **** **  done with MIFLINT.csv\n",
      "started data/03Temperature/MIGRNDRA.txt ** ** **** **  done with MIGRNDRA.csv\n",
      "started data/03Temperature/MILANSIN.txt ** ** **** **  done with MILANSIN.csv\n",
      "started data/03Temperature/MISTEMAR.txt ** ** **** **  done with MISTEMAR.csv\n",
      "started data/03Temperature/MNDULUTH.txt ** ** **** **  done with MNDULUTH.csv\n",
      "started data/03Temperature/MNMINPLS.txt ** ** **** **  done with MNMINPLS.csv\n",
      "started data/03Temperature/MOKANCTY.txt ** ** **** **  done with MOKANCTY.csv\n",
      "started data/03Temperature/MOSPRING.txt ** ** **** **  done with MOSPRING.csv\n",
      "started data/03Temperature/MOSTLOUI.txt ** ** **** **  done with MOSTLOUI.csv\n",
      "started data/03Temperature/MOULNBTR.txt ** ** **** **  done with MOULNBTR.csv\n",
      "started data/03Temperature/MSJACKSO.txt ** ** **** **  done with MSJACKSO.csv\n",
      "started data/03Temperature/MSKUALA.txt ** ** **** **  done with MSKUALA.csv\n",
      "started data/03Temperature/MSTUPELO.txt ** ** **** **  done with MSTUPELO.csv\n",
      "started data/03Temperature/MTBILLIN.txt ** ** **** **  done with MTBILLIN.csv\n",
      "started data/03Temperature/MTGRFALL.txt ** ** **** **  done with MTGRFALL.csv\n",
      "started data/03Temperature/MTHELENA.txt ** ** **** **  done with MTHELENA.csv\n",
      "started data/03Temperature/MTNOKCHT.txt ** ** **** **  done with MTNOKCHT.csv\n",
      "started data/03Temperature/MWLILNGW.txt ** ** **** **  done with MWLILNGW.csv\n",
      "started data/03Temperature/MXGUADLJ.txt ** ** **** **  done with MXGUADLJ.csv\n",
      "started data/03Temperature/MXMONTRY.txt ** ** **** **  done with MXMONTRY.csv\n",
      "started data/03Temperature/MXMXCITY.txt ** ** **** **  done with MXMXCITY.csv\n",
      "started data/03Temperature/MZMAPUTO.txt ** ** **** **  done with MZMAPUTO.csv\n",
      "started data/03Temperature/NCASHEVI.txt ** ** **** **  done with NCASHEVI.csv\n",
      "started data/03Temperature/NCCHARLO.txt ** ** **** **  done with NCCHARLO.csv\n",
      "started data/03Temperature/NCGRNSBO.txt ** ** **** **  done with NCGRNSBO.csv\n",
      "started data/03Temperature/NCRALEIG.txt ** ** **** **  done with NCRALEIG.csv\n",
      "started data/03Temperature/NDBISMAR.txt ** ** **** **  done with NDBISMAR.csv\n",
      "started data/03Temperature/NDFARGO.txt ** ** **** **  done with NDFARGO.csv\n",
      "started data/03Temperature/NELINCOL.txt ** ** **** **  done with NELINCOL.csv\n",
      "started data/03Temperature/NENPLATT.txt ** ** **** **  done with NENPLATT.csv\n",
      "started data/03Temperature/NEOMAHA.txt ** ** **** **  done with NEOMAHA.csv\n",
      "started data/03Temperature/NHCONCOR.txt ** ** **** **  done with NHCONCOR.csv\n",
      "started data/03Temperature/NILAGOS.txt ** ** **** **  done with NILAGOS.csv\n",
      "started data/03Temperature/NJATLCTY.txt ** ** **** **  done with NJATLCTY.csv\n",
      "started data/03Temperature/NJNEWARK.txt ** ** **** **  done with NJNEWARK.csv\n",
      "started data/03Temperature/NKMANAGU.txt ** ** **** **  done with NKMANAGU.csv\n",
      "started data/03Temperature/NLAMSTDM.txt ** ** **** **  done with NLAMSTDM.csv\n",
      "started data/03Temperature/NMALBUQU.txt ** ** **** **  done with NMALBUQU.csv\n",
      "started data/03Temperature/NMWNDHOK.txt ** ** **** **  done with NMWNDHOK.csv\n",
      "started data/03Temperature/NOOSLO.txt ** ** **** **  done with NOOSLO.csv\n",
      "started data/03Temperature/NPKTMNDU.txt ** ** **** **  done with NPKTMNDU.csv\n",
      "started data/03Temperature/NRNIAMEY.txt ** ** **** **  done with NRNIAMEY.csv\n",
      "started data/03Temperature/NVLASVEG.txt ** ** **** **  done with NVLASVEG.csv\n",
      "started data/03Temperature/NVRENO.txt ** ** **** **  done with NVRENO.csv\n",
      "started data/03Temperature/NYALBANY.txt ** ** **** **  done with NYALBANY.csv\n",
      "started data/03Temperature/NYBUFFAL.txt ** ** **** **  done with NYBUFFAL.csv\n",
      "started data/03Temperature/NYNEWYOR.txt ** ** **** **  done with NYNEWYOR.csv\n",
      "started data/03Temperature/NYROCHES.txt ** ** **** **  done with NYROCHES.csv\n",
      "started data/03Temperature/NYSYRACU.txt ** ** **** **  done with NYSYRACU.csv\n",
      "started data/03Temperature/NZACKLND.txt ** ** **** **  done with NZACKLND.csv\n",
      "started data/03Temperature/OHAKRON.txt ** ** **** **  done with OHAKRON.csv\n",
      "started data/03Temperature/OHCINCIN.txt ** ** **** **  done with OHCINCIN.csv\n",
      "started data/03Temperature/OHCLEVEL.txt ** ** **** **  done with OHCLEVEL.csv\n",
      "started data/03Temperature/OHCOLMBS.txt ** ** **** **  done with OHCOLMBS.csv\n",
      "started data/03Temperature/OHDAYTON.txt ** ** **** **  done with OHDAYTON.csv\n",
      "started data/03Temperature/OHTOLEDO.txt ** ** **** **  done with OHTOLEDO.csv\n",
      "started data/03Temperature/OHYOUNGS.txt ** ** **** **  done with OHYOUNGS.csv\n",
      "started data/03Temperature/OKOKLCTY.txt ** ** **** **  done with OKOKLCTY.csv\n",
      "started data/03Temperature/OKTULSA.txt ** ** **** **  done with OKTULSA.csv\n",
      "started data/03Temperature/OMMUSCAT.txt ** ** **** **  done with OMMUSCAT.csv\n",
      "started data/03Temperature/OREUGENE.txt ** ** **** **  done with OREUGENE.csv\n",
      "started data/03Temperature/ORMEDFOR.txt ** ** **** **  done with ORMEDFOR.csv\n",
      "started data/03Temperature/ORPORTLA.txt ** ** **** **  done with ORPORTLA.csv\n",
      "started data/03Temperature/ORSALEM.txt ** ** **** **  done with ORSALEM.csv\n",
      "started data/03Temperature/OSVIENNA.txt ** ** **** **  done with OSVIENNA.csv\n",
      "started data/03Temperature/PAALLENT.txt ** ** **** **  done with PAALLENT.csv\n",
      "started data/03Temperature/PAERIE.txt ** ** **** **  done with PAERIE.csv\n",
      "started data/03Temperature/PAHARRIS.txt ** ** **** **  done with PAHARRIS.csv\n",
      "started data/03Temperature/PAPHILAD.txt ** ** **** **  done with PAPHILAD.csv\n",
      "started data/03Temperature/PAPITTSB.txt ** ** **** **  done with PAPITTSB.csv\n",
      "started data/03Temperature/PAWILKES.txt ** ** **** **  done with PAWILKES.csv\n",
      "started data/03Temperature/PHMANILA.txt ** ** **** **  done with PHMANILA.csv\n",
      "started data/03Temperature/PKISLMBD.txt ** ** **** **  done with PKISLMBD.csv\n",
      "started data/03Temperature/PKKARACH.txt ** ** **** **  done with PKKARACH.csv\n",
      "started data/03Temperature/PLWARSAW.txt ** ** **** **  done with PLWARSAW.csv\n",
      "started data/03Temperature/PMPANAMA.txt ** ** **** **  done with PMPANAMA.csv\n",
      "started data/03Temperature/POLISBON.txt ** ** **** **  done with POLISBON.csv\n",
      "started data/03Temperature/PRLIMA.txt ** ** **** **  done with PRLIMA.csv\n",
      "started data/03Temperature/PRSANJUA.txt ** ** **** **  done with PRSANJUA.csv\n",
      "started data/03Temperature/QTDOHA.txt ** ** **** **  done with QTDOHA.csv\n",
      "started data/03Temperature/RAALMATY.txt ** ** **** **  done with RAALMATY.csv\n",
      "started data/03Temperature/RAASHBAD.txt ** ** **** **  done with RAASHBAD.csv\n",
      "started data/03Temperature/RABSHKEK.txt ** ** **** **  done with RABSHKEK.csv\n",
      "started data/03Temperature/RADUSNBE.txt ** ** **** **  done with RADUSNBE.csv\n",
      "started data/03Temperature/RATASKNT.txt ** ** **** **  done with RATASKNT.csv\n",
      "started data/03Temperature/RIPROVID.txt ** ** **** **  done with RIPROVID.csv\n",
      "started data/03Temperature/ROBCHRST.txt ** ** **** **  done with ROBCHRST.csv\n",
      "started data/03Temperature/RSMOSCOW.txt ** ** **** **  done with RSMOSCOW.csv\n",
      "started data/03Temperature/RSRIGA.txt ** ** **** **  done with RSRIGA.csv\n",
      "started data/03Temperature/RSTBLISI.txt ** ** **** **  done with RSTBLISI.csv\n",
      "started data/03Temperature/RSYERVAN.txt ** ** **** **  done with RSYERVAN.csv\n",
      "started data/03Temperature/SBCOLMBO.txt ** ** **** **  done with SBCOLMBO.csv\n",
      "started data/03Temperature/SCCHARLE.txt ** ** **** **  done with SCCHARLE.csv\n",
      "started data/03Temperature/SCCOLMBA.txt ** ** **** **  done with SCCOLMBA.csv\n",
      "started data/03Temperature/SDDHAHRN.txt ** ** **** **  done with SDDHAHRN.csv\n",
      "started data/03Temperature/SDRAPCTY.txt ** ** **** **  done with SDRAPCTY.csv\n",
      "started data/03Temperature/SDRIYADH.txt ** ** **** **  done with SDRIYADH.csv\n",
      "started data/03Temperature/SDSIOFAL.txt ** ** **** **  done with SDSIOFAL.csv\n",
      "started data/03Temperature/SGDAKAR.txt ** ** **** **  done with SGDAKAR.csv\n",
      "started data/03Temperature/SLFRETWN.txt ** ** **** **  done with SLFRETWN.csv\n",
      "started data/03Temperature/SMPRMRIB.txt ** ** **** **  done with SMPRMRIB.csv\n",
      "started data/03Temperature/SNSTKHLM.txt ** ** **** **  done with SNSTKHLM.csv\n",
      "started data/03Temperature/SPBILBAO.txt ** ** **** **  done with SPBILBAO.csv\n",
      "started data/03Temperature/SPBRCLNA.txt ** ** **** **  done with SPBRCLNA.csv\n",
      "started data/03Temperature/SPMADRID.txt ** ** **** **  done with SPMADRID.csv\n",
      "started data/03Temperature/SRSINGAP.txt ** ** **** **  done with SRSINGAP.csv\n",
      "started data/03Temperature/SWBERN.txt ** ** **** **  done with SWBERN.csv\n",
      "started data/03Temperature/SWGENEVA.txt ** ** **** **  done with SWGENEVA.csv\n",
      "started data/03Temperature/SWZURICH.txt ** ** **** **  done with SWZURICH.csv\n",
      "started data/03Temperature/SYDMSCUS.txt ** ** **** **  done with SYDMSCUS.csv\n",
      "started data/03Temperature/TGLOME.txt ** ** **** **  done with TGLOME.csv\n",
      "started data/03Temperature/THBNGKOK.txt ** ** **** **  done with THBNGKOK.csv\n",
      "started data/03Temperature/TNCHATTA.txt ** ** **** **  done with TNCHATTA.csv\n",
      "started data/03Temperature/TNDESALM.txt ** ** **** **  done with TNDESALM.csv\n",
      "started data/03Temperature/TNKNOXVI.txt ** ** **** **  done with TNKNOXVI.csv\n",
      "started data/03Temperature/TNMEMPHI.txt ** ** **** **  done with TNMEMPHI.csv\n",
      "started data/03Temperature/TNNASHVI.txt ** ** **** **  done with TNNASHVI.csv\n",
      "started data/03Temperature/TSTUNIS.txt ** ** **** **  done with TSTUNIS.csv\n",
      "started data/03Temperature/TUANKARA.txt ** ** **** **  done with TUANKARA.csv\n",
      "started data/03Temperature/TUISTNBL.txt ** ** **** **  done with TUISTNBL.csv\n",
      "started data/03Temperature/TWTAIPEI.txt ** ** **** **  done with TWTAIPEI.csv\n",
      "started data/03Temperature/TXABILEN.txt ** ** **** **  done with TXABILEN.csv\n",
      "started data/03Temperature/TXAMARIL.txt ** ** **** **  done with TXAMARIL.csv\n",
      "started data/03Temperature/TXAUSTIN.txt ** ** **** **  done with TXAUSTIN.csv\n",
      "started data/03Temperature/TXBROWNS.txt ** ** **** **  done with TXBROWNS.csv\n",
      "started data/03Temperature/TXCORPUS.txt ** ** **** **  done with TXCORPUS.csv\n",
      "started data/03Temperature/TXDALLAS.txt ** ** **** **  done with TXDALLAS.csv\n",
      "started data/03Temperature/TXELPASO.txt ** ** **** **  done with TXELPASO.csv\n",
      "started data/03Temperature/TXHOUSTO.txt ** ** **** **  done with TXHOUSTO.csv\n",
      "started data/03Temperature/TXLUBBOC.txt ** ** **** **  done with TXLUBBOC.csv\n",
      "started data/03Temperature/TXMIDLAN.txt ** ** **** **  done with TXMIDLAN.csv\n",
      "started data/03Temperature/TXSANANG.txt ** ** **** **  done with TXSANANG.csv\n",
      "started data/03Temperature/TXSANANT.txt ** ** **** **  done with TXSANANT.csv\n",
      "started data/03Temperature/TXWACO.txt ** ** **** **  done with TXWACO.csv\n",
      "started data/03Temperature/TXWICHFA.txt ** ** **** **  done with TXWICHFA.csv\n",
      "started data/03Temperature/UGKAMPAL.txt ** ** **** **  done with UGKAMPAL.csv\n",
      "started data/03Temperature/UKBELFST.txt ** ** **** **  done with UKBELFST.csv\n",
      "started data/03Temperature/UKLONDON.txt ** ** **** **  done with UKLONDON.csv\n",
      "started data/03Temperature/URKIEV.txt ** ** **** **  done with URKIEV.csv\n",
      "started data/03Temperature/UTSALTLK.txt ** ** **** **  done with UTSALTLK.csv\n",
      "started data/03Temperature/UYMNTVID.txt ** ** **** **  done with UYMNTVID.csv\n",
      "started data/03Temperature/VANORFOL.txt ** ** **** **  done with VANORFOL.csv\n",
      "started data/03Temperature/VARICHMO.txt ** ** **** **  done with VARICHMO.csv\n",
      "started data/03Temperature/VAROANOK.txt ** ** **** **  done with VAROANOK.csv\n",
      "started data/03Temperature/VNCARACS.txt ** ** **** **  done with VNCARACS.csv\n",
      "started data/03Temperature/VSHANOI.txt ** ** **** **  done with VSHANOI.csv\n",
      "started data/03Temperature/VTBURLIN.txt ** ** **** **  done with VTBURLIN.csv\n",
      "started data/03Temperature/WASEATTL.txt ** ** **** **  done with WASEATTL.csv\n",
      "started data/03Temperature/WASPOKAN.txt ** ** **** **  done with WASPOKAN.csv\n",
      "started data/03Temperature/WAYAKIMA.txt ** ** **** **  done with WAYAKIMA.csv\n",
      "started data/03Temperature/WIGREBAY.txt ** ** **** **  done with WIGREBAY.csv\n",
      "started data/03Temperature/WIMADISO.txt ** ** **** **  done with WIMADISO.csv\n",
      "started data/03Temperature/WIMILWAU.txt ** ** **** **  done with WIMILWAU.csv\n",
      "started data/03Temperature/WVCHARLE.txt ** ** **** **  done with WVCHARLE.csv\n",
      "started data/03Temperature/WVELKINS.txt ** ** **** **  done with WVELKINS.csv\n",
      "started data/03Temperature/WYCASPER.txt ** ** **** **  done with WYCASPER.csv\n",
      "started data/03Temperature/WYCHEYEN.txt ** ** **** **  done with WYCHEYEN.csv\n",
      "started data/03Temperature/YGBLGRDE.txt ** ** **** **  done with YGBLGRDE.csv\n",
      "started data/03Temperature/YGPRISTN.txt ** ** **** **  done with YGPRISTN.csv\n",
      "started data/03Temperature/YGSKOPJE.txt ** ** **** **  done with YGSKOPJE.csv\n",
      "started data/03Temperature/YGZAGREB.txt ** ** **** **  done with YGZAGREB.csv\n",
      "started data/03Temperature/ZACAPTWN.txt ** ** **** **  done with ZACAPTWN.csv\n",
      "started data/03Temperature/ZBLUSAKA.txt ** ** **** **  done with ZBLUSAKA.csv\n"
     ]
    }
   ],
   "source": [
    "# Importing the os library\n",
    "import os\n",
    "# The path for listing items\n",
    "path = 'data/03Temperature'\n",
    "# The list of items\n",
    "files = os.listdir(path)\n",
    "# Loop to print each filename separately\n",
    "for filename in files:\n",
    "    full_path = path+'/'+filename\n",
    "    createcsv(full_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below this point -- Work still going on!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n",
      "            temp\n",
      "date            \n",
      "1995-01-01  73.4\n",
      "1995-01-02  70.4\n",
      "1995-01-03  72.7\n",
      "1995-01-04  76.3\n",
      "1995-01-05  76.8\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = 'data/03Temperature'\n",
    "# The list of items\n",
    "files = os.listdir(path)\n",
    "# Loop to print each filename separately\n",
    "all_csvs = [path+'/'+filename for filename in files]\n",
    "print(len(all_csvs))\n",
    "no1stCSV = all_csvs.pop()\n",
    "\n",
    "####### WORK ON the picking only non us files and then pick correct column name and perform left join.\n",
    "df_nonUS = pd.read_csv(no1stCSV, index_col=\"date\")\n",
    "print(df_nonUS.head())\n",
    "\n",
    "\n",
    "print(len(all_csvs))\n",
    "\n",
    "# left = pd.DataFrame({\n",
    "#     'Sr': [6, 7, 8, 9, 2],\n",
    "#     'Name': ['Span', 'Suchu', 'Vetts', 'Appu', 'Sri']})\n",
    "# right = pd.DataFrame({\n",
    "#     'Sr': [6, 7, 8, 9, 20],\n",
    "#     'Name': ['fil', 'mil', 'sil', 'pil', 'gil']})\n",
    "# print(pd.merge(left, right, on='Sr', how='outer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name\n",
       "Sr     \n",
       "6   fil\n",
       "7   mil\n",
       "8   sil\n",
       "9   pil\n",
       "20  gil"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "left = pd.DataFrame({\n",
    "    'Sr': [6, 7, 8, 9, 2],\n",
    "    'Name': ['Span', 'Suchu', 'Vetts', 'Appu', 'Sri']}) #, index='Sr')\n",
    "left.set_index('Sr')\n",
    "right = pd.DataFrame({\n",
    "    'Sr': [6, 7, 8, 9, 20],\n",
    "    'Name': ['fil', 'mil', 'sil', 'pil', 'gil']}) #,index='Sr')\n",
    "right.set_index('Sr')\n",
    "# print(pd.merge(left, right, on='Sr', how='outer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() missing 1 required positional argument: 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23228/1157617198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: join() missing 1 required positional argument: 'other'"
     ]
    }
   ],
   "source": [
    "pd.merge(left, right, left_index=True, right_index=True)\n",
    "left.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4831faad42022cb3b0932f3bf965c0323cdc750e5e185dff2cc12c78d9e2dc2b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MLTryOuts-SDuJ_iQf': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
